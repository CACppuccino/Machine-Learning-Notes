#Brief History of Machine Learning#

##origin:http://www.erogol.com/brief-history-machine-learning/  
###翻译：Cup  
###一些有可能翻译不准确的terms  
Hebbian Learning theory
Recurrent Neural Network-递归神经网络    
##正文  
机器学习时间轴：http://www.erogol.com/wp-content/uploads/2014/05/test.jpg  
  
  由于科学之最初立场，科技与人工智能，科学家们跟随着Blaise Pascal和Von Leibniz的脚步思考是否有一种机器，拥有与人类相同的智能。著名作者如Jules Verne，Frank Baum(绿野仙踪)，Marry Shelly(弗兰肯斯坦)，George Lucas(星球大战)幻想着人造人有着与人类相似甚至更强的能力，在不同情况下拥有着人性化的能力。  
Pascal的机器表演加减法：http://www.erogol.com/wp-content/uploads/2014/05/Arts_et_Metiers_Pascaline_dsc03869.jpg  
  机器学习(Machine Learning)是人工智能（AI）非常热门的一个方向，无论是在学术界还是工业界。公司，大学投入了大量的资源来提升他们在这方面的知识。近期的在此领域的进步，在很多任务中取得了实实在在的成果。  
  在这里我将分享一个机器学习的时间轴，并标注出其中的一些里程碑（尽管不一定完全）。  
  向着机器学习前进的第一步是由Hebb在1949年迈出的，基于一个神经心理学的学习公式。它被称为Hebbian学习原理。简单来讲，它加紧了节点和递归神经网络的相关性。
  它记住了所有网络上的共性并在之后如同人的记忆一般工作。正式地来讲，关于它的论述如下：  
  **让我们假设一个反射活动的持久性或重复性倾向于引诱持续的细胞发生改变从而增加它的稳定性。...
  当一个神经细胞A的轴突足够近来使细胞B兴奋并重复或持续地参与激活它，一些增长的过程或新陈代谢的改变会在其中一个或双方细胞中发生。
  这样的话，A的效率在刺激B的同时会升高。[1]**  
  在1952年，Arthur Samuel在IBM研发出了会下跳棋的程序。该程序能够观察位置并学习得出一个
  模糊的模型，指导其为以后的情况作出更好的移动。Samuel与程序下了很多次棋，并发现程序能够随着时间的增长而下的更好。  
  
  
